{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db202f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def locate_and_split(filepath : str):\n",
    "    loader = PyPDFLoader(file_path=filepath)\n",
    "    docs = loader.load_and_split()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "    chunks = text_splitter.split_documents(documents=docs)\n",
    "    print(\"Chunking...\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'PyPDF2',\n",
       " 'creator': 'PyPDF',\n",
       " 'creationdate': '',\n",
       " 'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       " 'publisher': 'Curran Associates, Inc.',\n",
       " 'language': 'en-US',\n",
       " 'created': '2017',\n",
       " 'eventtype': 'Poster',\n",
       " 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.',\n",
       " 'title': 'Attention is All you Need',\n",
       " 'date': '2017',\n",
       " 'moddate': '2018-02-12T21:22:10-08:00',\n",
       " 'published': '2017',\n",
       " 'type': 'Conference Proceedings',\n",
       " 'firstpage': '5998',\n",
       " 'book': 'Advances in Neural Information Processing Systems 30',\n",
       " 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)',\n",
       " 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett',\n",
       " 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       " 'lastpage': '6008',\n",
       " 'source': 'D:\\\\Project\\\\RAG\\\\docs\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf',\n",
       " 'total_pages': 11,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = locate_and_split(r\"D:\\Project\\RAG\\docs\\NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
    "chunks[0].metadata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654c23a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GenModel' from 'HybridSearchRAG.model' (d:\\Project\\RAG\\HybridSearchRAG\\model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mHybridSearchRAG\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenModel\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mHybridSearchRAG\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_hybrid_retriever\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mHybridSearchRAG\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRADE_DOCS, FINAL_ANSWER\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'GenModel' from 'HybridSearchRAG.model' (d:\\Project\\RAG\\HybridSearchRAG\\model.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "from operator import add\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "from HybridSearchRAG.model import GenModel\n",
    "from HybridSearchRAG.retriever import get_hybrid_retriever\n",
    "from HybridSearchRAG.prompts import GRADE_DOCS, FINAL_ANSWER\n",
    "\n",
    "llm = GenModel()\n",
    "retriever = get_hybrid_retriever()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages : List[BaseMessage]\n",
    "    question : str\n",
    "    documents : List[Document]\n",
    "    relevance : str\n",
    "    result : str\n",
    "\n",
    "def retriever_node(state : AgentState) -> AgentState:\n",
    "    print(\"--- RETRIEVING DOCUMENTS ---\")\n",
    "    query = state['question']\n",
    "    result = retriever.invoke(query)\n",
    "    print(f\"--- RETRIEVED {len(result)} DOCUMENTS ---\")\n",
    "    return {\"documents\" : result}\n",
    "\n",
    "def grade_docs(state : AgentState) -> AgentState:\n",
    "    print(\"--- GRADING DOCUMENTS ---\")  \n",
    "    question = state[\"question\"]\n",
    "    docs = state[\"documents\"]\n",
    "    prompt = GRADE_DOCS.format_prompt(question=question, documents=docs)\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    if \"yes\" in result.lower():\n",
    "        print(\"--- GRADE: DOCUMENTS ARE RELEVANT ---\")\n",
    "        return {\"relevance\": \"YES\"}\n",
    "    else:\n",
    "        print(\"--- GRADE: DOCUMENTS ARE NOT RELEVANT ---\")\n",
    "        return {\"relevance\": \"NO\"}\n",
    "    \n",
    "def generation(state : AgentState) -> AgentState:\n",
    "    print(\"--- GENERATING ANSWER ---\")\n",
    "\n",
    "    query = state[\"question\"]\n",
    "    docs = state['documents']\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    prompt = FINAL_ANSWER.format_prompt(context=formatted_docs, question=query)\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    print(\"--- ANSWER GENERATED ---\")\n",
    "\n",
    "    return {\"result\" : result}\n",
    "\n",
    "def should_continue(state : AgentState):\n",
    "    relevance = state[\"relevance\"]\n",
    "\n",
    "    if \"yes\" in relevance.lower().strip():\n",
    "        return \"CONTINUE\"\n",
    "    return \"END\"\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"RETRIEVER NODE\", retriever_node)\n",
    "graph.add_node(\"GRADE NODE\", grade_docs)\n",
    "graph.add_node(\"GENERATION NODE\", generation)\n",
    "\n",
    "graph.add_edge(START, \"RETRIEVER NODE\")\n",
    "graph.add_edge(\"RETRIEVER NODE\", \"GRADE NODE\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"GRADE NODE\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"CONTINUE\" : \"GENERATION NODE\",\n",
    "        \"END\" : END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"GENERATION NODE\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e6228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
